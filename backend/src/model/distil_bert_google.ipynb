{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ktrain\n",
    "from ktrain import text\n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21589\n"
     ]
    }
   ],
   "source": [
    "csv_file = '../../data/merged_ktrain_google_en.csv'\n",
    "data = pd.read_csv(csv_file).values\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 3\n",
    "learning_rate = 5e-5\n",
    "batch_size = 32\n",
    "max_length = 21\n",
    "max_words = 25000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_test_data(data, split=0.1, random_seed=42):\n",
    "    np.random.seed(random_seed)\n",
    "    np.random.shuffle(data)\n",
    "    split_item = math.floor(split * len(data))\n",
    "    print('split at: ', split_item)\n",
    "    x_test, y_test = data[:split_item, 0], data[:split_item, 1:]\n",
    "    x_train, y_train = data[split_item:, 0], data[split_item:, 1:]\n",
    "    return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split at:  1079\n",
      "20510 20510 1079 1079\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train, x_val, y_val = split_test_data(data, split=0.05, random_seed=4242)\n",
    "print(len(x_train), len(y_train), len(x_val), len(y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 2.1765891966465034, 1: 0.49869915140905, 2: 1.8679417122040072}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import class_weight\n",
    "def generate_balanced_weights(y_train):\n",
    "    y_labels = [y.argmax() for y in y_train]\n",
    "    class_weights = class_weight.compute_class_weight('balanced', np.unique(y_labels), y_labels)\n",
    "    weight_dict = {}\n",
    "    for key in range(len(class_weights)):\n",
    "        weight_dict[key] = class_weights[key]\n",
    "    return weight_dict\n",
    "\n",
    "class_weight_dict = generate_balanced_weights(y_train)\n",
    "print(class_weight_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing train...\n",
      "language: en\n",
      "train sequence lengths:\n",
      "\tmean : 9\n",
      "\t95percentile : 15\n",
      "\t99percentile : 18\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Multi-Label? False\n",
      "preprocessing test...\n",
      "language: en\n",
      "test sequence lengths:\n",
      "\tmean : 9\n",
      "\t95percentile : 15\n",
      "\t99percentile : 19\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MODEL = 'distilbert-base-uncased'\n",
    "transformer = text.Transformer(MODEL, maxlen=max_length, class_names=['less', 'equal', 'more'])\n",
    "train_data = transformer.preprocess_train(x_train, y_train)\n",
    "val_data = transformer.preprocess_test(x_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = transformer.get_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner = ktrain.get_learner(model, train_data=train_data, val_data=val_data, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simulating training for different learning rates... this may take a few moments...\n",
      "Train for 640 steps\n",
      "Epoch 1/2\n",
      "  0/640 [..............................] - ETA: 0s"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'loss'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mon_batch\u001b[0;34m(self, step, mode, size)\u001b[0m\n\u001b[1;32m    783\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 784\u001b[0;31m         \u001b[0;32myield\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    785\u001b[0m       \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    127\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 98\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    567\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    631\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 632\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    633\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2363\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1611\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1692\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-e87c2d9ee5f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlearner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr_find\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshow_plot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ktrain/core.py\u001b[0m in \u001b[0;36mlr_find\u001b[0;34m(self, start_lr, lr_mult, max_epochs, stop_factor, show_plot, suggest, restore_weights_only, verbose)\u001b[0m\n\u001b[1;32m    542\u001b[0m                                 \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m                                 \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 544\u001b[0;31m                                 verbose=verbose)\n\u001b[0m\u001b[1;32m    545\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m             \u001b[0;31m# re-load current weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ktrain/lroptimize/lrfinder.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(self, train_data, steps_per_epoch, use_gen, start_lr, lr_mult, max_epochs, batch_size, workers, use_multiprocessing, verbose)\u001b[0m\n\u001b[1;32m    117\u001b[0m                    \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m                    \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m                    callbacks=[callback])\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             self.model.fit(train_data[0], train_data[1],\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    179\u001b[0m             batch_end=step * batch_size + current_batch_size)\n\u001b[1;32m    180\u001b[0m       \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m       \u001b[0mstep\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     97\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthrow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m                 \u001b[0;31m# Suppress StopIteration *unless* it's the same exception that\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mon_batch\u001b[0;34m(self, step, mode, size)\u001b[0m\n\u001b[1;32m    786\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data_exhausted'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    787\u001b[0m           self.callbacks._call_batch_hook(\n\u001b[0;32m--> 788\u001b[0;31m               mode, 'end', step, batch_logs)\n\u001b[0m\u001b[1;32m    789\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    237\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m       \u001b[0mbatch_hook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m       \u001b[0mbatch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delta_ts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt_before_callbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    526\u001b[0m     \"\"\"\n\u001b[1;32m    527\u001b[0m     \u001b[0;31m# For backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    529\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mdoc_controls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_subclass_implementers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ktrain/lroptimize/lrfinder.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(batch, logs)\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_lr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m         \u001b[0mcallback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLambdaCallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ktrain/lroptimize/lrfinder.py\u001b[0m in \u001b[0;36mon_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;31m# Log the loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_num\u001b[0m \u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mavg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbeta\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mavg_loss\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbeta\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'loss'"
     ]
    }
   ],
   "source": [
    "learner.lr_find(show_plot=True, max_epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "begin training using onecycle policy with max lr of 5e-05...\n",
      "Train for 641 steps, validate for 34 steps\n",
      "Epoch 1/10\n",
      "641/641 [==============================] - 44s 69ms/step - loss: 0.1983 - accuracy: 0.9109 - val_loss: 2.5230 - val_accuracy: 0.6024\n",
      "Epoch 2/10\n",
      "641/641 [==============================] - 43s 67ms/step - loss: 0.1542 - accuracy: 0.9302 - val_loss: 2.6559 - val_accuracy: 0.5598\n",
      "Epoch 3/10\n",
      "641/641 [==============================] - 43s 67ms/step - loss: 0.1353 - accuracy: 0.9361 - val_loss: 2.6037 - val_accuracy: 0.5366\n",
      "Epoch 4/10\n",
      "641/641 [==============================] - 44s 68ms/step - loss: 0.1307 - accuracy: 0.9396 - val_loss: 2.7147 - val_accuracy: 0.5700\n",
      "Epoch 5/10\n",
      "641/641 [==============================] - 43s 68ms/step - loss: 0.1452 - accuracy: 0.9360 - val_loss: 2.6686 - val_accuracy: 0.5468\n",
      "Epoch 6/10\n",
      "641/641 [==============================] - 43s 67ms/step - loss: 0.1190 - accuracy: 0.9481 - val_loss: 3.0406 - val_accuracy: 0.5440\n",
      "Epoch 7/10\n",
      "641/641 [==============================] - 44s 68ms/step - loss: 0.0671 - accuracy: 0.9706 - val_loss: 3.6633 - val_accuracy: 0.5579\n",
      "Epoch 8/10\n",
      "641/641 [==============================] - 44s 68ms/step - loss: 0.0435 - accuracy: 0.9813 - val_loss: 3.8594 - val_accuracy: 0.5839\n",
      "Epoch 9/10\n",
      "641/641 [==============================] - 44s 68ms/step - loss: 0.0269 - accuracy: 0.9892 - val_loss: 3.8397 - val_accuracy: 0.5533\n",
      "Epoch 10/10\n",
      "641/641 [==============================] - 43s 68ms/step - loss: 0.0146 - accuracy: 0.9939 - val_loss: 4.1723 - val_accuracy: 0.5820\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f1c409a5e80>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.fit_onecycle(5e-5, epochs=10, class_weight=class_weight_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "id:783 | loss:7.45 | true:more | pred:equal)\n",
      "\n",
      "----------\n",
      "id:548 | loss:7.33 | true:more | pred:equal)\n",
      "\n",
      "----------\n",
      "id:375 | loss:7.3 | true:more | pred:equal)\n",
      "\n",
      "----------\n",
      "id:966 | loss:7.13 | true:more | pred:equal)\n",
      "\n",
      "----------\n",
      "id:907 | loss:7.08 | true:more | pred:equal)\n",
      "\n",
      "----------\n",
      "id:742 | loss:7.07 | true:more | pred:equal)\n",
      "\n",
      "----------\n",
      "id:143 | loss:7.04 | true:more | pred:equal)\n",
      "\n",
      "----------\n",
      "id:412 | loss:7.04 | true:more | pred:equal)\n",
      "\n",
      "----------\n",
      "id:0 | loss:7.02 | true:more | pred:equal)\n",
      "\n",
      "----------\n",
      "id:994 | loss:6.95 | true:more | pred:equal)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "learner.view_top_losses(n=10, preproc=transformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = ktrain.get_predictor(learner.model, preproc=transformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    table.eli5-weights tr:hover {\n",
       "        filter: brightness(85%);\n",
       "    }\n",
       "</style>\n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "        \n",
       "\n",
       "    \n",
       "\n",
       "        \n",
       "\n",
       "        \n",
       "    \n",
       "        \n",
       "        \n",
       "    \n",
       "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
       "            <b>\n",
       "    \n",
       "        y=equal\n",
       "    \n",
       "</b>\n",
       "\n",
       "    \n",
       "    (probability <b>0.999</b>, score <b>6.778</b>)\n",
       "\n",
       "top features\n",
       "        </p>\n",
       "    \n",
       "    <table class=\"eli5-weights\"\n",
       "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
       "        <thead>\n",
       "        <tr style=\"border: none;\">\n",
       "            \n",
       "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n",
       "                    Contribution<sup>?</sup>\n",
       "                </th>\n",
       "            \n",
       "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "            \n",
       "        </tr>\n",
       "        </thead>\n",
       "        <tbody>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +6.819\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        Highlighted in text (sum)\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "        \n",
       "\n",
       "        \n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 99.45%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.040\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        &lt;BIAS&gt;\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "\n",
       "        </tbody>\n",
       "    </table>\n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n",
       "    <p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n",
       "        <span style=\"background-color: hsl(120, 100.00%, 83.72%); opacity: 0.86\" title=\"0.862\">european</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 60.00%); opacity: 1.00\" title=\"3.114\">semester</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 73.31%); opacity: 0.91\" title=\"1.746\">autumn</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 90.91%); opacity: 0.82\" title=\"0.375\">package</span><span style=\"opacity: 0.80\">: </span><span style=\"background-color: hsl(120, 100.00%, 74.10%); opacity: 0.91\" title=\"1.673\">creating</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 76.38%); opacity: 0.89\" title=\"1.467\">an</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 90.10%); opacity: 0.83\" title=\"0.423\">economy</span>\n",
       "    </p>\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.explain(x_train[741])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.22      0.20      0.21       156\n",
      "           1       0.70      0.76      0.73       727\n",
      "           2       0.28      0.21      0.24       196\n",
      "\n",
      "    accuracy                           0.58      1079\n",
      "   macro avg       0.40      0.39      0.39      1079\n",
      "weighted avg       0.55      0.58      0.57      1079\n",
      "\n"
     ]
    }
   ],
   "source": [
    "confusion = learner.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# print confusion matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "labels = ['less', 'equal', 'more']\n",
    "cm_df = pd.DataFrame(confusion, labels, labels)\n",
    "sn.set(font_scale=1.1, font='Arial')\n",
    "ax = sn.heatmap(cm_df, cmap=\"Blues\", annot=True, annot_kws={\"size\": 11}, cbar=False)\n",
    "ax.set_xlabel(\"Actual\")\n",
    "ax.set_ylabel(\"Predicted\")\n",
    "ax.set_title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
